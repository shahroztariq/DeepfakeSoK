{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067cf5a5-c051-479a-9ff5-23d8e0440916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from tensorflow.python.keras.backend import clear_session\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.python.keras.utils.layer_utils import print_summary\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import numpy as np\n",
    "# from resnet_convlstm import ResNet\n",
    "from Utility_functions import FreezeBatchNormalization\n",
    "from datetime import datetime as dt\n",
    "from DFVDSequence import DFVDSequence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.python.keras import layers\n",
    "\n",
    "\n",
    "dataset_dir='../datasets/'\n",
    "# from src.cl_basic import cl_basic\n",
    "import ipykernel\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# Choose GPU NUMBERS [0, 1, 2, 3]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1b1fb6-550c-4869-830d-4520b40513c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8b0c35-14c2-4dab-85fa-8b748089595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_best_threshold(scores, labels):\n",
    "        fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        best_acc = 0\n",
    "        best_thresh = None\n",
    "        for i, thresh in enumerate(thresholds):\n",
    "            # compute accuracy for this threshold\n",
    "            pred_labels = [1 if s >= thresh else 0 for s in scores]\n",
    "            acc = sum([1 if pred_labels[j] == labels[j] else 0 for j in range(len(labels))]) / len(labels)\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_thresh = thresh\n",
    "        return best_thresh, roc_auc\n",
    "\n",
    "\n",
    "def eval_state(probs, labels, thr):\n",
    "    predict = probs >= thr\n",
    "    labels = np.array(labels)\n",
    "    TN = np.sum((labels == 0) & (predict == False))\n",
    "    FN = np.sum((labels == 1) & (predict == False))\n",
    "    FP = np.sum((labels == 0) & (predict == True))\n",
    "    TP = np.sum((labels == 1) & (predict == True))\n",
    "    return TN, FN, FP, TP\n",
    "\n",
    "def evaluate(pretrained_model, data_iter):\n",
    "    # predictions = pretrained_model.predict_generator(data_iter, verbose=1)\n",
    "    # prob_list = predictions[:, 1]\n",
    "    # label_list = data_iter.classes\n",
    "    \n",
    "    shape_pred_count = 0\n",
    "    shape_input_count = 0\n",
    "    prob_list = []\n",
    "    label_list = []\n",
    "    for batch_x, batch_y in tqdm(data_iter):\n",
    "        # Process the batch inputs and labels\n",
    "        # ...\n",
    "        predictions = pretrained_model.predict(batch_x)\n",
    "        shape_pred_count += len(predictions)\n",
    "        shape_input_count += len(batch_y)\n",
    "        \n",
    "        prob_list.append(predictions)\n",
    "        label_list.append(batch_y)\n",
    "        \n",
    "    prob_list = np.concatenate(prob_list)[:, 1]\n",
    "    label_list = np.concatenate(label_list)[:, 1].astype(np.int32)\n",
    "\n",
    "    print(\"At threshold = 0.5\")\n",
    "    best_thresh = 0.5\n",
    "    TN, FN, FP, TP = eval_state(probs=prob_list, labels=label_list, thr=best_thresh)\n",
    "    if (FN + TP == 0):\n",
    "        FRR = 1.0\n",
    "        FAR = FP / float(FP + TN)\n",
    "        TPR = 0\n",
    "    elif(FP + TN == 0):\n",
    "        FAR = 1.0\n",
    "        FRR = FN / float(FN + TP)\n",
    "        TPR = TP / float(TP + FN)\n",
    "    else:\n",
    "        FAR = FP / float(FP + TN)\n",
    "        FRR = FN / float(FN + TP)\n",
    "        TPR = TP / float(TP + FN)\n",
    "\n",
    "    ACC = (TN + TP) / (TN + FN + FP + TP)\n",
    "    HTER = (FAR + FRR) / 2.0\n",
    "    print(f\"HTER: {HTER*100:.2f}\")\n",
    "    print(f\"FAR: {FAR*100:.2f}\")\n",
    "    print(f\"TPR: {TPR*100:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "    np.save('pred_tmp.npy', prob_list)\n",
    "    np.save('lb_tmp.npy', label_list)\n",
    "    print(\"Max values\", len(prob_list), np.max(prob_list), np.min(prob_list), np.max(label_list), np.min(label_list))\n",
    "\n",
    "\n",
    "    best_thresh, AUC = find_best_threshold(scores=prob_list, labels=label_list)\n",
    "    print(f\"At best threshold = {best_thresh:.4f}\")\n",
    "    TN, FN, FP, TP = eval_state(probs=prob_list, labels=label_list, thr=best_thresh)\n",
    "    if (FN + TP == 0):\n",
    "        FRR = 1.0\n",
    "        FAR = FP / float(FP + TN)\n",
    "        TPR = 0\n",
    "    elif(FP + TN == 0):\n",
    "        FAR = 1.0\n",
    "        FRR = FN / float(FN + TP)\n",
    "        TPR = TP / float(TP + FN)\n",
    "    else:\n",
    "        FAR = FP / float(FP + TN)\n",
    "        FRR = FN / float(FN + TP)\n",
    "        TPR = TP / float(TP + FN)\n",
    "\n",
    "\n",
    "    HTER = (FAR + FRR) / 2.0\n",
    "    ACC_best = (TN + TP) / (TN + FN + FP + TP)\n",
    "    print(f\"HTER: {HTER*100:.2f}\")\n",
    "    print(f\"FAR: {FAR*100:.2f}\")\n",
    "    print(f\"TPR: {TPR*100:.2f}\")\n",
    "    print(f\"AUC: {AUC*100:.2f}\")\n",
    "    return (ACC*100, ACC_best*100, AUC*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23914e-04bf-46fc-8044-e08eb3b02dfb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = load_model('../pretrained-weight/clrnet/CLR_ALL_Ebest.hdf5')\n",
    "is_training = False\n",
    "top_k_layers=120\n",
    "model,df=FreezeBatchNormalization(is_training,top_k_layers,model)\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "adam_fine = Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam_fine,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e096f7-179c-4394-bb37-42391e1b914c",
   "metadata": {},
   "source": [
    "### generated dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862954f5-ff32-48b7-9202-21cff83d428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_per_video_per_batch=5\n",
    "frames_per_video=10\n",
    "image_size=128\n",
    "test_video_per_batch=10\n",
    "data_augmentation=False\n",
    "training=False\n",
    "\n",
    "\n",
    "print(\"TEST UPON SETTING\")\n",
    "out_results = pd.DataFrame({\n",
    "    \"Dataset\":[], \"Acc\": [], \"Acc_best\": [], \"AUC\": []\n",
    "})\n",
    "for data_name in (\"DeepFaceLab\", \"Dfaker\", \"Faceswap\", \"FOM_Animation\", \"FOM_Faceswap\", \"FSGAN\", \"LightWeight\"):\n",
    "\n",
    "    X_val,y_val,class_weights_val=create_sequence([f'../datasets/Stablelized/{data_name}/',\n",
    "                                               '../datasets/Stablelized/real/'],frames_per_video_per_batch,frames_per_video)\n",
    "\n",
    "    val_it=DFVDSequence(X_val,y_val,test_video_per_batch,frames_per_video_per_batch,image_size,data_augmentation,training)\n",
    " \n",
    "    ACC, ACC_best, AUC = evaluate(pretrained_model=model, data_iter=val_it)\n",
    "    out_results = out_results.append({\"Dataset\":data_name, \n",
    "                                        \"Acc\": np.round(ACC,2), \n",
    "                                        \"Acc_best\": np.round(ACC_best,2), \n",
    "                                        \"AUC\": np.round(AUC,2)}, ignore_index=True)\n",
    "    \n",
    "out_results = out_results.append({\"Dataset\":\"Avg\", \n",
    "                                    \"Acc\": f\"{out_results.Acc.mean():.2f} ({out_results.Acc.std():.2f})\", \n",
    "                                    \"Acc_best\": f\"{out_results.Acc_best.mean():.2f} ({out_results.Acc_best.std():.2f})\", \n",
    "                                    \"AUC\": f\"{out_results.AUC.mean():.2f} ({out_results.AUC.std():.2f})\"}, \n",
    "                                    ignore_index=True)\n",
    "out_results.to_csv(f\"predictions/clrnet.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF1",
   "language": "python",
   "name": "tf1_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
